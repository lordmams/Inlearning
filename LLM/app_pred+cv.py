import streamlit as st
import pandas as pd
import joblib
import openai
import pdfplumber
import json

# === CONFIGURATION API GROQ ===
openai.api_key = "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"  # Mets ta vraie cl√© Groq ici
openai.api_base = "https://api.groq.com/openai/v1"

# === CHARGEMENT DU MOD√àLE ===
model_details = joblib.load("best_model_rff.pkl")
model = model_details["model"]
scaler = model_details["scaler"]
label_encoder = model_details["label_encoder"]
feature_mappings = model_details["feature_mappings"]
features = model_details["features"]


# === ANALYSE DU CV PAR L'IA ===
def extract_cv_info_from_pdf(pdf_file):
    with pdfplumber.open(pdf_file) as pdf:
        cv_text = "\n".join([page.extract_text() or "" for page in pdf.pages])
    cv_text = cv_text[:8000]

    prompt = f"""
Analyse ce CV et retourne ces informations sous forme de JSON :
- √¢ge (si connu)
- email
- t√©l√©phone
- niveau acad√©mique (Bac, DUT, Licence, Master, Ing√©nieur)
- ann√©es d'exp√©rience
- domaine d'√©tude (Informatique, Marketing, etc.)
- langage pr√©f√©r√©
- mode d'apprentissage (En ligne, Pr√©sentiel, Alternance, Hybride)
- genre (M ou F)
Voici le texte :
\"\"\"
{cv_text}
\"\"\"
    """

    response = openai.ChatCompletion.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "Tu es un assistant RH."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )

    content = response["choices"][0]["message"]["content"].strip()
    st.subheader("üì¶ R√©ponse brute de Groq (pour debug)")
    st.code(content, language="markdown")

    if "```json" in content:
        content = content.split("```json")[1].split("```")[0].strip()
    elif "```" in content:
        content = content.split("```")[1].split("```")[0].strip()

    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        raise ValueError(f"Le mod√®le n‚Äôa pas retourn√© un JSON valide. D√©tail : {e}")


def safe_index(lst, value):
    try:
        return lst.index(value)
    except:
        return None


# === INTERFACE ===
st.title("ü§ñ Pr√©diction du niveau d'exp√©rience via CV ou formulaire")

uploaded_cv = st.file_uploader("üìÑ Uploader un CV PDF", type=["pdf"])
cv_data = {}

if uploaded_cv and st.button("Analyser le CV avec l'IA"):
    with st.spinner("Analyse du CV en cours..."):
        try:
            cv_data = extract_cv_info_from_pdf(uploaded_cv)

            translations = {
                "academic_level": "niveau acad√©mique",
                "years_of_experience": "ann√©es d'exp√©rience",
                "domain_of_study": "domaine d'√©tude",
                "preferred_language": "langage pr√©f√©r√©",
                "learning_mode": "mode d'apprentissage",
            }
            for src, dest in translations.items():
                if src in cv_data:
                    cv_data[dest] = cv_data[src]

            normalisation = {
                "niveau acad√©mique": {
                    "Master 2": "Master",
                    "Master 1": "Master",
                    "Licence 3": "Licence",
                    "Licence 2": "Licence",
                    "DUT 2": "DUT",
                    "Baccalaur√©at": "Bac",
                },
                "domaine d'√©tude": {
                    "Data Engineer": "Informatique",
                    "Computer Science": "Informatique",
                    "Business": "Gestion",
                },
            }
            for field, mapping in normalisation.items():
                if field in cv_data and cv_data[field] in mapping:
                    cv_data[field] = mapping[cv_data[field]]

            st.success("‚úÖ Analyse r√©ussie !")
        except Exception as e:
            st.error(f"‚ùå Erreur : {e}")
            cv_data = {}

st.subheader("üìù Compl√®te ou modifie les champs si besoin :")

# === FORMULAIRE ===
age = st.number_input(
    "√Çge",
    min_value=10,
    max_value=100,
    value=int(cv_data["√¢ge"]) if "√¢ge" in cv_data and cv_data["√¢ge"] else None,
)

gender_options = list(feature_mappings["gender"].keys())
gender = st.selectbox(
    "Genre", gender_options, index=safe_index(gender_options, cv_data.get("genre")) or 0
)

lang_options = list(feature_mappings["preferred_language"].keys())
preferred_language = st.selectbox(
    "Langage pr√©f√©r√©",
    lang_options,
    index=safe_index(lang_options, cv_data.get("langage pr√©f√©r√©")) or 0,
)

mode_options = list(feature_mappings["learning_mode"].keys())
learning_mode = st.selectbox(
    "Mode d'apprentissage",
    mode_options,
    index=safe_index(mode_options, cv_data.get("mode d'apprentissage")) or 0,
)

level_options = list(feature_mappings["highest_academic_level"].keys())
highest_academic_level = st.selectbox(
    "Niveau acad√©mique",
    level_options,
    index=safe_index(level_options, cv_data.get("niveau acad√©mique")) or 0,
)

total_experience_years = st.number_input(
    "Ann√©es d'exp√©rience",
    min_value=0.0,
    max_value=50.0,
    value=float(cv_data.get("ann√©es d'exp√©rience") or 0.0),
    step=0.5,
)

field_options = list(feature_mappings["fields_of_study"].keys())
fields_of_study = st.selectbox(
    "Domaine d'√©tude",
    field_options,
    index=safe_index(field_options, cv_data.get("domaine d'√©tude")) or 0,
)

# === PR√âDICTION ===
if st.button("üîÆ Pr√©dire le niveau d'exp√©rience"):
    if not all(
        [
            age,
            gender,
            preferred_language,
            learning_mode,
            highest_academic_level,
            total_experience_years,
            fields_of_study,
        ]
    ):
        st.warning("‚ö†Ô∏è Merci de remplir tous les champs pour lancer la pr√©diction.")
    else:
        input_data = pd.DataFrame(
            {
                "age": [age],
                "gender": [feature_mappings["gender"][gender]],
                "preferred_language": [
                    feature_mappings["preferred_language"][preferred_language]
                ],
                "learning_mode": [feature_mappings["learning_mode"][learning_mode]],
                "highest_academic_level": [
                    feature_mappings["highest_academic_level"][highest_academic_level]
                ],
                "total_experience_years": [total_experience_years],
                "fields_of_study": [
                    feature_mappings["fields_of_study"][fields_of_study]
                ],
            }
        )

        input_scaled = scaler.transform(input_data[features])
        prediction = model.predict(input_scaled)
        prediction_label = label_encoder.inverse_transform(prediction)[0]
        prediction_proba = model.predict_proba(input_scaled)[0]

        st.success(f"üß† Niveau estim√© : **{prediction_label}**")
        st.bar_chart(prediction_proba)
